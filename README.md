# Agente de An√°lise de Investimentos RAG

## Vis√£o Geral

O Agente de An√°lise de Investimentos RAG √© uma aplica√ß√£o avan√ßada que utiliza Retrieval-Augmented Generation (RAG) para an√°lise inteligente de documentos financeiros. A aplica√ß√£o combina processamento de documentos PDF, embeddings vetoriais, e modelos de linguagem para fornecer insights autom√°ticos, conversa√ß√£o inteligente e an√°lises detalhadas de investimentos.

## Arquitetura do Sistema

### Diagrama de Arquitetura

```mermaid
graph TB
    U[Usuario] --> ST[Streamlit Frontend]
    ST --> FM[File Manager]
    ST --> VM[Vector Manager]
    ST --> LLM[LLM Services]
    
    FM --> RN[reports_new/]
    FM --> RP[reports_processed/]
    
    VM --> CB[ChromaDB]
    VM --> OE[OpenAI Embeddings]
    
    LLM --> OA[OpenAI API]
    LLM --> LC[LangChain]
    
    CB --> VS[vector_store_chroma/]
    
    subgraph "RAG Pipeline"
        PDF[PDF Documents] --> TXT[Text Extraction]
        TXT --> CHK[Text Chunking]
        CHK --> EMB[Embeddings Generation]
        EMB --> IDX[Vector Indexing]
        IDX --> CB
    end
    
    subgraph "Query Processing"
        Q[User Query] --> RET[Vector Retrieval]
        RET --> CTX[Context Assembly]
        CTX --> GEN[Response Generation]
        GEN --> R[Response]
    end
```

### Diagrama de Componentes UML

```mermaid
graph LR
    subgraph "Frontend Layer"
        ST[Streamlit App]
        UI[User Interface]
        TABS[Tab Components]
    end
    
    subgraph "Business Logic Layer"
        FM[FileHandler]
        VM[VectorStoreManager]
        LLM[LLMServices]
        CFG[Config]
    end
    
    subgraph "Data Layer"
        FS[File System]
        CB[ChromaDB]
        VS[Vector Store]
    end
    
    subgraph "External Services"
        OAI[OpenAI API]
        DDG[DuckDuckGo Search]
    end
    
    ST --> FM
    ST --> VM
    ST --> LLM
    FM --> FS
    VM --> CB
    VM --> VS
    LLM --> OAI
    LLM --> DDG
    
    CFG --> FM
    CFG --> VM
    CFG --> LLM
```

### Diagrama de Sequ√™ncia - Processamento de Documento

```mermaid
sequenceDiagram
    participant U as Usuario
    participant ST as Streamlit
    participant FM as FileManager
    participant VM as VectorManager
    participant CB as ChromaDB
    participant OAI as OpenAI
    
    U->>ST: Upload PDF
    ST->>FM: save_uploaded_files()
    FM->>FS: Salvar em reports_new/
    
    U->>ST: Processar Relat√≥rios
    ST->>FM: get_new_reports_to_process()
    FM-->>ST: Lista de arquivos
    
    loop Para cada arquivo
        ST->>VM: is_document_already_processed()
        VM->>CB: Verificar duplicatas
        CB-->>VM: Resultado verifica√ß√£o
        
        alt N√£o √© duplicata
            ST->>VM: add_documents_from_file()
            VM->>VM: Carregar PDF
            VM->>VM: Dividir em chunks
            VM->>OAI: Gerar embeddings
            OAI-->>VM: Embeddings
            VM->>CB: Armazenar no vector store
            CB-->>VM: Confirma√ß√£o
            ST->>FM: move_processed_file()
            FM->>FS: Mover para reports_processed/
        else √â duplicata
            ST->>U: Arquivo j√° processado
        end
    end
    
    ST-->>U: Processamento conclu√≠do
```

### Diagrama de Sequ√™ncia - Gera√ß√£o de Insights

```mermaid
sequenceDiagram
    participant U as Usuario
    participant ST as Streamlit
    participant LLM as LLMServices
    participant VM as VectorManager
    participant CB as ChromaDB
    participant OAI as OpenAI
    
    U->>ST: Solicitar Insights
    ST->>VM: count_documents()
    VM-->>ST: N√∫mero de chunks
    
    alt Documentos dispon√≠veis
        U->>ST: Escolher tipo de insight
        ST->>VM: get_retriever()
        VM-->>ST: Retriever configurado
        
        alt Resumo Executivo
            ST->>LLM: generate_market_summary()
            LLM->>VM: retriever.invoke(query)
            VM->>CB: Busca por similaridade
            CB-->>VM: Documentos relevantes
            VM-->>LLM: Contexto recuperado
            LLM->>OAI: Prompt + Contexto
            OAI-->>LLM: Resposta gerada
            LLM-->>ST: Resumo executivo
        else M√©tricas Chave
            ST->>LLM: extract_key_metrics()
            LLM->>VM: retriever.invoke(query)
            VM->>CB: Busca dados num√©ricos
            CB-->>VM: Documentos com m√©tricas
            VM-->>LLM: Contexto com dados
            LLM->>OAI: Prompt de extra√ß√£o
            OAI-->>LLM: M√©tricas estruturadas
            LLM-->>ST: Dados extra√≠dos
        else An√°lise Detalhada
            ST->>LLM: generate_insights_from_documents()
            loop Para cada query de insight
                LLM->>VM: retriever.invoke(specific_query)
                VM->>CB: Busca espec√≠fica
                CB-->>VM: Documentos relacionados
                VM-->>LLM: Contexto espec√≠fico
                LLM->>OAI: Prompt especializado
                OAI-->>LLM: Insight gerado
            end
            LLM-->>ST: Conjunto de insights
        end
        
        ST-->>U: Insights apresentados
    else Sem documentos
        ST-->>U: Aviso para processar documentos
    end
```

### Diagrama de Fluxo de Dados

```mermaid
flowchart TD
    START([In√≠cio]) --> UPLOAD[Upload de PDFs]
    UPLOAD --> CHECK{Arquivo j√° processado?}
    
    CHECK -->|N√£o| PROCESS[Processar Documento]
    CHECK -->|Sim| SKIP[Pular Processamento]
    
    PROCESS --> EXTRACT[Extrair Texto]
    EXTRACT --> CHUNK[Dividir em Chunks]
    CHUNK --> EMBED[Gerar Embeddings]
    EMBED --> STORE[Armazenar no ChromaDB]
    STORE --> MOVE[Mover para Processados]
    
    SKIP --> MOVE
    MOVE --> READY[Sistema Pronto]
    
    READY --> QUERY{Tipo de Uso}
    
    QUERY -->|Chat| CHAT[Conversa√ß√£o]
    QUERY -->|Visualizar| VIEW[Visualizar PDF]
    QUERY -->|Insights| INSIGHTS[Gerar Insights]
    
    CHAT --> RETRIEVE1[Recuperar Contexto]
    RETRIEVE1 --> AGENT[Agente Conversacional]
    AGENT --> RESPONSE1[Resposta ao Usuario]
    
    VIEW --> DISPLAY[Exibir PDF/Texto]
    DISPLAY --> RESPONSE2[Visualiza√ß√£o]
    
    INSIGHTS --> TYPE{Tipo de Insight}
    TYPE -->|Resumo| SUMMARY[Resumo Executivo]
    TYPE -->|M√©tricas| METRICS[Extrair M√©tricas]
    TYPE -->|Detalhado| DETAILED[An√°lise Detalhada]
    
    SUMMARY --> RETRIEVE2[Buscar Documentos]
    METRICS --> RETRIEVE3[Buscar Dados Num√©ricos]
    DETAILED --> RETRIEVE4[Buscar por Categorias]
    
    RETRIEVE2 --> GENERATE1[Gerar com IA]
    RETRIEVE3 --> GENERATE2[Extrair com IA]
    RETRIEVE4 --> GENERATE3[Analisar com IA]
    
    GENERATE1 --> RESPONSE3[Insights Gerados]
    GENERATE2 --> RESPONSE3
    GENERATE3 --> RESPONSE3
    
    RESPONSE1 --> END([Fim])
    RESPONSE2 --> END
    RESPONSE3 --> END
```

## Funcionalidades Principais

### 1. Sele√ß√£o de Modelo LLM
- **Dropdown interativo** na barra lateral para escolha do modelo
- **6 modelos dispon√≠veis**: GPT-4o-mini, GPT-4o, GPT-4-turbo, GPT-3.5-turbo, GPT-4, GPT-5
- **Indicadores visuais** mostrando custo/qualidade de cada modelo
- **Aplica√ß√£o universal**: modelo selecionado usado em chat, insights e resumos
- **Interface intuitiva** com descri√ß√µes e recomenda√ß√µes de uso

### 2. Upload e Processamento de Documentos
- Upload de m√∫ltiplos PDFs simultaneamente
- Detec√ß√£o autom√°tica de duplicatas
- Processamento com divis√£o inteligente em chunks
- Gera√ß√£o de embeddings vetoriais
- Armazenamento persistente no ChromaDB

### 3. Interface de Conversa√ß√£o
- Chat interativo com agente IA
- Respostas baseadas no conte√∫do dos documentos
- Integra√ß√£o com busca web (DuckDuckGo)
- Mem√≥ria de conversa√ß√£o persistente
- Processamento de linguagem natural

### 4. Visualiza√ß√£o de Documentos
- Visualizador de PDF integrado
- Extra√ß√£o e exibi√ß√£o de texto formatado
- Busca dentro do texto
- Download de arquivos
- Estat√≠sticas de documento

### 5. Gera√ß√£o de Insights Autom√°ticos
- **Resumo Executivo**: An√°lise geral do mercado
- **M√©tricas Chave**: Extra√ß√£o de dados num√©ricos
- **An√°lise Detalhada**: Insights categorizados por:
  - FIIs Principais
  - Rendimentos e Dividendos
  - Setores de Investimento
  - Recomenda√ß√µes
  - Riscos e Oportunidades
  - Tend√™ncias de Mercado

### 6. Funcionalidades de √Åudio
- Text-to-Speech (TTS) para resumos
- Text-to-Speech para documentos completos
- Concatena√ß√£o autom√°tica de √°udio
- Controles de reprodu√ß√£o nativos
- Download de arquivos de √°udio

## Stack Tecnol√≥gico

### Frontend
- **Streamlit**: Interface web reativa
- **HTML/CSS**: Customiza√ß√µes de interface
- **JavaScript**: Componentes interativos

### Backend
- **Python 3.12**: Linguagem principal
- **LangChain**: Framework para LLM
- **ChromaDB**: Banco de dados vetorial
- **PyPDF**: Processamento de PDF
- **pydub**: Manipula√ß√£o de √°udio

### Intelig√™ncia Artificial
- **Modelos LLM Selecion√°veis**: 
  - GPT-4o-mini (padr√£o - r√°pido e econ√¥mico)
  - GPT-4o (mais inteligente, mais caro)
  - GPT-4-turbo (avan√ßado)
  - GPT-3.5-turbo (econ√¥mico)
  - GPT-4 (cl√°ssico)
  - GPT-5 (mais avan√ßado e caro)
- **OpenAI Embeddings**: text-embedding-3-small
- **OpenAI TTS**: S√≠ntese de voz (modelo tts-1)
- **DuckDuckGo Search**: Busca web complementar

### Infraestrutura
- **Docker**: Containeriza√ß√£o
- **Docker Compose**: Orquestra√ß√£o
- **Environment Variables**: Configura√ß√£o segura

## Como Usar a Aplica√ß√£o

### Para Usu√°rios

1. **Acesso Initial**
   - Abra a aplica√ß√£o em http://localhost:8501
   - Visualize a interface com 3 abas principais

2. **Sele√ß√£o do Modelo LLM**
   - Na barra lateral, se√ß√£o "ü§ñ Configura√ß√£o do Modelo"
   - Escolha entre 6 modelos dispon√≠veis no dropdown:
     - **GPT-4o-mini**: R√°pido e econ√¥mico (recomendado para uso geral)
     - **GPT-3.5-turbo**: Mais econ√¥mico para tarefas simples
     - **GPT-4o**: Maior qualidade para an√°lises complexas
     - **GPT-4-turbo** e **GPT-4**: Modelos premium
     - **GPT-5**: Mais avan√ßado (maior custo)
   - Observe os indicadores de custo/qualidade abaixo do seletor

3. **Carregamento de Documentos**
   - Na barra lateral, use "Carregar Novos Relat√≥rios"
   - Selecione um ou mais arquivos PDF
   - Aguarde confirma√ß√£o do upload

4. **Processamento**
   - Clique em "Integrar Novos Relat√≥rios ao Agente"
   - Observe o status de cada arquivo (Novo/J√° Processado)
   - Aguarde o processamento RAG completar

5. **Uso das Funcionalidades**
   - **Modelo ativo**: Indicado no topo de cada aba (chat e insights)

   **Aba "Conversar com Agente":**
   - Digite perguntas sobre seus relat√≥rios
   - Receba respostas contextualizadas
   - Hist√≥rico de conversa√ß√£o mantido

   **Aba "Visualizador de Relat√≥rio":**
   - Selecione um relat√≥rio processado
   - Escolha entre visualiza√ß√£o PDF ou texto
   - Use funcionalidades de busca e download

   **Aba "Insights dos Relat√≥rios":**
   - Clique em "Resumo Executivo" para an√°lise geral
   - Use "M√©tricas Chave" para dados espec√≠ficos
   - "An√°lise Detalhada" para insights categorizados

6. **Recursos Avan√ßados**
   - Download de insights como arquivos .txt
   - Gera√ß√£o e download de √°udios TTS
   - Visualiza√ß√£o de estat√≠sticas do sistema

### Para Administradores

1. **Configura√ß√£o de Ambiente**
   - Configure OPENAI_API_KEY no arquivo .env
   - Ajuste par√¢metros em config.py conforme necess√°rio
   - Verifique depend√™ncias FFmpeg para TTS

2. **Monitoramento**
   - Acompanhe logs de processamento
   - Monitore uso do ChromaDB
   - Verifique m√©tricas de performance

3. **Manuten√ß√£o**
   - Limpeza peri√≥dica de arquivos duplicados
   - Backup do vector store
   - Atualiza√ß√µes de depend√™ncias

## Explica√ß√£o T√©cnica Detalhada

### Arquitetura RAG (Retrieval-Augmented Generation)

A aplica√ß√£o implementa um pipeline RAG completo:

1. **Ingest√£o de Documentos**
   ```python
   # Fluxo de processamento
   PDF ‚Üí PyPDFLoader ‚Üí TextSplitter ‚Üí OpenAIEmbeddings ‚Üí ChromaDB
   ```

2. **Recupera√ß√£o (Retrieval)**
   ```python
   # Busca por similaridade
   Query ‚Üí Embedding ‚Üí ChromaDB.similarity_search ‚Üí Documentos Relevantes
   ```

3. **Gera√ß√£o (Generation)**
   ```python
   # Prompt engineering
   Query + Context ‚Üí OpenAI GPT ‚Üí Resposta Fundamentada
   ```

### Componentes Principais

#### VectorStoreManager
- Gerencia embeddings e armazenamento vetorial
- Implementa detec√ß√£o de duplicatas
- Otimiza consultas por similaridade
- Mant√©m metadados de documentos

```python
class VectorStoreManager:
    def add_documents_from_file(self, file_path):
        # Verifica√ß√£o de duplicatas
        # Chunking inteligente
        # Gera√ß√£o de embeddings
        # Armazenamento no ChromaDB
```

#### LLMServices
- Encapsula intera√ß√µes com OpenAI
- **Suporte a m√∫ltiplos modelos LLM**: Todas as fun√ß√µes aceitam par√¢metro `model_name` opcional
- Implementa diferentes tipos de prompts especializados
- Gerencia gera√ß√£o de insights com modelo selecion√°vel
- Controla s√≠ntese de voz

```python
def generate_insights_from_documents(retriever, model_name=None):
    # Usa modelo selecionado pelo usu√°rio ou padr√£o
    # M√∫ltiplas queries especializadas
    # Recupera√ß√£o contextual
    # Gera√ß√£o de insights categorizados

def setup_agent(retriever, model_name=None):
    # Agente conversacional com modelo configur√°vel
```

#### FileHandler
- Gerencia fluxo de arquivos
- Implementa sistema anti-duplica√ß√£o
- Controla persist√™ncia de dados
- Organiza diret√≥rios de trabalho

### Otimiza√ß√µes Implementadas

1. **Performance**
   - Chunking otimizado (1000 chars, 200 overlap)
   - Retrieval configur√°vel (k=4 padr√£o)
   - Cache de embeddings no ChromaDB
   - Processamento ass√≠ncrono de √°udio

2. **Qualidade**
   - **Sele√ß√£o de modelo otimizada**: 6 op√ß√µes para diferentes necessidades
   - **GPT-4o-mini padr√£o**: Equilibra qualidade e custo
   - **Modelos premium dispon√≠veis**: Para an√°lises mais complexas
   - Prompts especializados por tipo de insight
   - Temperature ajustada por caso de uso
   - Valida√ß√£o de entrada e sa√≠da
   - Tratamento robusto de erros

3. **Usabilidade**
   - **Seletor de modelo intuitivo**: Dropdown com descri√ß√µes e indicadores
   - **Indicadores visuais**: Modelo ativo exibido em tempo real
   - **Recomenda√ß√µes de uso**: Guias para escolha do modelo apropriado
   - Interface reativa com Streamlit
   - Progress bars para opera√ß√µes longas
   - Downloads diretos de conte√∫do
   - Feedback visual consistente

### Seguran√ßa e Boas Pr√°ticas

1. **Dados Sens√≠veis**
   - API keys em vari√°veis de ambiente
   - .gitignore para dados locais
   - N√£o exposi√ß√£o de embeddings

2. **Valida√ß√£o**
   - Verifica√ß√£o de tipos de arquivo
   - Sanitiza√ß√£o de inputs
   - Tratamento de exce√ß√µes

3. **Performance**
   - Lazy loading de componentes
   - Gerenciamento eficiente de mem√≥ria
   - Cleanup autom√°tico de recursos

## Configura√ß√£o e Instala√ß√£o

### Pr√©-requisitos
- Python 3.12+
- Docker e Docker Compose
- FFmpeg (para funcionalidades TTS)
- Chave API da OpenAI

### Instala√ß√£o via Docker (Recomendado)

1. **Clone o reposit√≥rio**
   ```bash
   git clone <repository-url>
   cd rag-investor-agent
   ```

2. **Configure vari√°veis de ambiente**
   ```bash
   cp .env.example .env
   # Edite .env com sua OPENAI_API_KEY
   ```

3. **Execute com Docker**
   ```bash
   docker-compose up --build
   ```

### Instala√ß√£o Local

1. **Ambiente Python**
   ```bash
   python -m venv venv
   source venv/bin/activate  # Linux/macOS
   # ou
   venv\Scripts\activate     # Windows
   ```

2. **Instale depend√™ncias**
   ```bash
   pip install -r requirements.txt
   ```

3. **Execute aplica√ß√£o**
   ```bash
   streamlit run app.py
   ```

## Estrutura do Projeto

```
rag-investor-agent/
‚îú‚îÄ‚îÄ app.py                 # Interface principal Streamlit
‚îú‚îÄ‚îÄ config.py             # Configura√ß√µes centralizadas
‚îú‚îÄ‚îÄ file_handler.py       # Gerenciamento de arquivos
‚îú‚îÄ‚îÄ llm_services.py       # Servi√ßos de IA e LLM
‚îú‚îÄ‚îÄ vector_store.py       # Gerenciador do banco vetorial
‚îú‚îÄ‚îÄ memory.py            # Gerenciamento de mem√≥ria
‚îú‚îÄ‚îÄ prompts.py           # Templates de prompts
‚îú‚îÄ‚îÄ requirements.txt     # Depend√™ncias Python
‚îú‚îÄ‚îÄ Dockerfile           # Configura√ß√£o Docker
‚îú‚îÄ‚îÄ docker-compose.yml   # Orquestra√ß√£o de servi√ßos
‚îú‚îÄ‚îÄ .env                # Vari√°veis de ambiente
‚îú‚îÄ‚îÄ .gitignore          # Arquivos ignorados pelo Git
‚îú‚îÄ‚îÄ CLAUDE.md           # Documenta√ß√£o t√©cnica
‚îú‚îÄ‚îÄ reports_new/        # Arquivos pendentes
‚îú‚îÄ‚îÄ reports_processed/  # Arquivos processados
‚îî‚îÄ‚îÄ vector_store_chroma/ # Banco de dados vetorial
```

## Contribui√ß√£o

### Desenvolvimento
1. Fa√ßa fork do projeto
2. Crie branch para feature (`git checkout -b feature/nova-funcionalidade`)
3. Commit mudan√ßas (`git commit -am 'Adiciona nova funcionalidade'`)
4. Push para branch (`git push origin feature/nova-funcionalidade`)
5. Abra Pull Request

### Testes
- Execute `python test_rag.py` para testar pipeline RAG
- Use `python test_insights.py` para validar gera√ß√£o de insights
- Execute `python test_duplicates.py` para verificar anti-duplica√ß√£o

## Licen√ßa

Este projeto est√° licenciado sob a licen√ßa MIT. Veja o arquivo LICENSE para mais detalhes.

## Contato

Para quest√µes t√©cnicas ou sugest√µes de melhorias, entre em contato com a equipe de desenvolvimento.