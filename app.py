"""Ponto de Entrada Principal - Interface do Usu√°rio (Streamlit)

Orquestra as chamadas para os outros m√≥dulos e renderiza a UI.
"""
import os
import base64
import streamlit as st
from dotenv import load_dotenv

# M√≥dulos locais
import config
import file_handler
from vector_store import VectorStoreManager
import llm_services
from langchain.text_splitter import RecursiveCharacterTextSplitter

# Carregar vari√°veis e configurar ambiente
load_dotenv()
config.ensure_directories_exist()

def display_pdf(file_path):
    """Exibe informa√ß√µes do PDF e oferece op√ß√µes de visualiza√ß√£o."""
    if not os.path.exists(file_path):
        st.error(f"Erro: Arquivo PDF n√£o encontrado em: {file_path}")
        return

    try:
        # Obter informa√ß√µes do arquivo
        file_size = os.path.getsize(file_path)
        file_name = os.path.basename(file_path)
        
        # Mostrar informa√ß√µes do arquivo
        st.success(f"üìÑ **Arquivo encontrado:** {file_name}")
        st.info(f"üìä **Tamanho:** {file_size / (1024*1024):.1f} MB")
        
        # Ler o arquivo
        with open(file_path, "rb") as f:
            pdf_bytes = f.read()
        
        # Bot√£o de download principal (mais confi√°vel)
        st.markdown("""
        <div style="text-align: center; margin: 30px 0;">
            <h3 style="color: #4CAF50;">üìñ Visualizar PDF</h3>
            <p style="color: #666;">Use o bot√£o abaixo para baixar e abrir o PDF</p>
        </div>
        """, unsafe_allow_html=True)
        
        # Bot√£o principal de download estilizado
        col1, col2, col3 = st.columns([1, 2, 1])
        with col2:
            st.download_button(
                label="üì• BAIXAR E ABRIR PDF",
                data=pdf_bytes,
                file_name=file_name,
                mime="application/pdf",
                use_container_width=True,
                type="primary"
            )
        
        # Instru√ß√µes melhoradas
        st.markdown("""
        ### üìã Como visualizar o PDF:
        
        **M√©todo Recomendado (mais confi√°vel):**
        1. **Clique em "BAIXAR E ABRIR PDF"** acima
        2. O arquivo ser√° baixado automaticamente 
        3. Abra o arquivo baixado com seu visualizador de PDF preferido
        
        **M√©todos Alternativos:**
        """)
        
        # M√©todos alternativos
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**üåê Tentar abrir no navegador:**")
            # Criar data URL para teste
            base64_pdf = base64.b64encode(pdf_bytes).decode('utf-8')
            data_url = f"data:application/pdf;base64,{base64_pdf}"
            
            if st.button("üîó Tentar abrir no navegador", use_container_width=True):
                st.markdown(f"""
                <script>
                    window.open('{data_url}', '_blank');
                </script>
                """, unsafe_allow_html=True)
                
                st.markdown(f"""
                <a href="{data_url}" target="_blank" 
                   style="display: block; 
                          text-align: center; 
                          background-color: #0066cc; 
                          color: white;
                          padding: 8px;
                          text-decoration: none;
                          border-radius: 4px;
                          margin-top: 8px;">
                    Se n√£o abriu, clique aqui
                </a>
                """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("**üìÑ Ver como texto:**")
            if st.button("üìñ Ler como texto formatado", use_container_width=True):
                st.session_state.action = ('read_pdf_text', file_path)
                st.rerun()
        
        # Informa√ß√µes adicionais
        st.markdown("""
        ---
        ### ‚ÑπÔ∏è Informa√ß√µes importantes:
        
        - **Navegadores modernos** podem bloquear PDFs incorporados por seguran√ßa
        - **Baixar o arquivo** √© sempre a op√ß√£o mais confi√°vel
        - **Visualizadores recomendados:** Adobe Reader, navegador padr√£o, visualizador do sistema
        """)
        
        # Mostrar pr√©via do iframe como √∫ltima op√ß√£o
        with st.expander("üîß Op√ß√µes Avan√ßadas - Tentar visualiza√ß√£o incorporada"):
            st.warning("‚ö†Ô∏è Esta op√ß√£o pode n√£o funcionar em todos os navegadores")
            
            if st.button("Tentar visualiza√ß√£o incorporada"):
                try:
                    # Tentar iframe simples
                    st.components.v1.html(f"""
                    <iframe src="{data_url}" 
                            width="100%" 
                            height="600px"
                            style="border: 1px solid #ddd;">
                        <p>Seu navegador n√£o suporta visualiza√ß√£o de PDF incorporado.</p>
                    </iframe>
                    """, height=620)
                except Exception as e:
                    st.error(f"Visualiza√ß√£o incorporada falhou: {e}")
                    
    except Exception as e:
        st.error(f"Erro ao processar o PDF: {e}")
        st.info("üí° Tente usar a op√ß√£o 'Ler PDF (Texto Formatado)' como alternativa.")

def main():
    st.set_page_config(page_title="Agente de Investimentos", page_icon="üìä", layout="wide")
    st.title("üìä Agente de An√°lise de Investimentos PRO")

    # Inicializar o gerenciador do vector store
    vector_manager = VectorStoreManager()

    # Inicializar hist√≥rico de chat no session_state
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # --- Barra Lateral (Controles) ---
    with st.sidebar:
        st.header("Controles")
        
        # Seletor de Modelo LLM
        st.subheader("ü§ñ Configura√ß√£o do Modelo")
        selected_model = st.selectbox(
            "Escolha o modelo LLM:",
            options=list(config.AVAILABLE_LLM_MODELS.keys()),
            format_func=lambda x: config.AVAILABLE_LLM_MODELS[x],
            index=0,  # GPT-4o-mini como padr√£o
            help="Modelos mais avan√ßados s√£o mais inteligentes, mas consomem mais tokens."
        )
        
        # Mostrar informa√ß√µes sobre o modelo selecionado
        if selected_model == "gpt-5":
            st.info("üéØ **Modelo Mais Avan√ßado** - M√°xima qualidade, maior custo")
        elif selected_model in ["gpt-4o", "gpt-4-turbo", "gpt-4"]:
            st.info("üí∞ **Modelo Premium** - Maior qualidade, maior custo")
        elif selected_model == "gpt-3.5-turbo":
            st.info("üöÄ **Modelo Econ√¥mico** - R√°pido e barato")
        else:
            st.info("‚ö° **Modelo Balanceado** - √ìtima rela√ß√£o qualidade/custo")
        
        # Armazenar o modelo selecionado no session state
        st.session_state.selected_model = selected_model
        
        st.subheader("1. Carregar Novos Relat√≥rios")
        uploaded_files = st.file_uploader("Selecione arquivos PDF", accept_multiple_files=True, type="pdf")
        if uploaded_files:
            count = file_handler.save_uploaded_files(uploaded_files)
            st.success(f"{count} arquivo(s) pronto(s) para processamento.")

        st.subheader("2. Processar Relat√≥rios")
        
        # Mostrar arquivos pendentes com status
        new_reports = file_handler.get_new_reports_to_process()
        if new_reports:
            st.write("**Arquivos pendentes:**")
            for report_path in new_reports:
                file_name = os.path.basename(report_path)
                is_duplicate = vector_manager.is_document_already_processed(report_path)
                if is_duplicate:
                    st.warning(f"üö´ {file_name} - J√Å PROCESSADO")
                else:
                    st.info(f"üìÑ {file_name} - Novo")
        
        if st.button("Integrar Novos Relat√≥rios ao Agente"):
            if not new_reports:
                st.info("Nenhum novo relat√≥rio para processar.")
            else:
                with st.spinner(f"Processando {len(new_reports)} relat√≥rio(s)..."):
                    processed_count = 0
                    skipped_count = 0
                    
                    for report_path in new_reports:
                        chunks_added = vector_manager.add_documents_from_file(report_path)
                        if chunks_added > 0:
                            processed_count += 1
                            file_handler.move_processed_file(report_path)
                            st.success(f"‚úÖ {os.path.basename(report_path)} - {chunks_added} chunks adicionados")
                        else:
                            skipped_count += 1
                            # Ainda mover arquivo mesmo se foi pulado (j√° processado)
                            file_handler.move_processed_file(report_path)
                            st.info(f"‚è≠Ô∏è {os.path.basename(report_path)} - Pulado (duplicata)")
                    
                    if processed_count > 0:
                        st.success(f"üéâ {processed_count} arquivo(s) processado(s) com sucesso!")
                    if skipped_count > 0:
                        st.info(f"‚è≠Ô∏è {skipped_count} arquivo(s) pulado(s) (j√° processados)")
        
        # Mostrar informa√ß√µes do Vector Store
        with st.expander("üìä Informa√ß√µes do Banco de Dados Vetorial (RAG)"):
            try:
                doc_count = vector_manager.count_documents()
                collection_info = vector_manager.get_collection_info()
                processed_docs_info = vector_manager.get_processed_documents_info()
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üìÑ Chunks totais", doc_count)
                with col2:
                    st.metric("üìÅ Documentos √∫nicos", len(processed_docs_info))
                with col3:
                    st.metric("üß† Modelo Embeddings", config.EMBEDDING_MODEL_NAME)
                
                if doc_count > 0:
                    st.success("‚úÖ Vector Store funcionando corretamente!")
                    
                    # Mostrar documentos processados
                    if processed_docs_info:
                        st.write("**üìã Documentos processados:**")
                        for doc_name, info in processed_docs_info.items():
                            chunk_count = info['chunk_count']
                            total_chunks = info['total_chunks']
                            st.write(f"‚Ä¢ **{doc_name}**: {chunk_count} chunks")
                    
                    # Teste de busca simples
                    if st.button("üîç Testar busca no RAG"):
                        test_query = "investimento"
                        results = vector_manager.search_similarity(test_query, k=2)
                        if results:
                            st.write(f"**Teste de busca por '{test_query}':**")
                            for i, (doc, score) in enumerate(results):
                                st.write(f"**Resultado {i+1}** (Score: {score:.3f})")
                                st.write(f"Fonte: {doc.metadata.get('source_file', 'N/A')}")
                                st.write(f"Conte√∫do: {doc.page_content[:200]}...")
                                st.write("---")
                else:
                    st.warning("‚ö†Ô∏è Nenhum documento foi processado ainda.")
                    
            except Exception as e:
                st.error(f"‚ùå Erro ao acessar vector store: {e}")
        
        st.divider()

        st.subheader("3. Explorar Relat√≥rio Espec√≠fico")
        processed_reports = file_handler.get_all_processed_reports()
        selected_report = st.selectbox("Selecione um relat√≥rio:", options=processed_reports, index=None, placeholder="Escolha um arquivo...")

        if selected_report:
            report_path = os.path.join(config.REPORTS_PROCESSED_DIR, selected_report)
            st.markdown("**A√ß√µes:**")
            col1, col2 = st.columns(2)
            col3, col4 = st.columns(2)
            col5, col6 = st.columns(2)

            if col1.button("üìñ Ler PDF (Visualizador)", key=f"read_pdf_viewer_{selected_report}"):
                st.session_state.action = ('read_pdf_viewer', report_path)
            if col2.button("üìÑ Ler PDF (Texto Formatado)", key=f"read_pdf_text_{selected_report}"):
                st.session_state.action = ('read_pdf_text', report_path)
            if col3.button("üìù Gerar Resumo", key=f"summarize_{selected_report}"):
                st.session_state.action = ('summarize', report_path)
            if col4.button("üéß Ouvir Resumo", key=f"listen_summary_{selected_report}"):
                st.session_state.action = ('listen_summary', report_path)
            if col5.button("üéß Ouvir Relat√≥rio Completo", key=f"listen_full_{selected_report}", help="Pode levar v√°rios minutos para textos longos."):
                st.session_state.action = ('listen_full', report_path)

    # --- Abas Principais ---
    tab_agent, tab_explorer, tab_insights = st.tabs([
        "üó£Ô∏è Conversar com Agente", 
        "üìÑ Visualizador de Relat√≥rio", 
        "üí° Insights dos Relat√≥rios"
    ])

    with tab_agent:
        # Mostrar modelo ativo
        selected_model = st.session_state.get('selected_model', config.LLM_MODEL_NAME)
        st.subheader("üó£Ô∏è Conversar com o Agente")
        st.info(f"ü§ñ **Modelo ativo:** {config.AVAILABLE_LLM_MODELS.get(selected_model, selected_model)}")
        
        # Exibir mensagens anteriores do chat
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        user_question = st.chat_input("Fa√ßa sua pergunta...")
        if user_question:
            st.session_state.messages.append({"role": "user", "content": user_question})
            with st.chat_message("user"):
                st.markdown(user_question)

            with st.spinner("O Agente est√° pensando..."):
                # Usar o modelo selecionado pelo usu√°rio
                selected_model = st.session_state.get('selected_model', config.LLM_MODEL_NAME)
                agent_executor = llm_services.setup_agent(vector_manager.get_retriever(), model_name=selected_model)
                try:
                    # Usar invoke para compatibilidade com mem√≥ria
                    response = agent_executor.invoke({"input": user_question})["output"]
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    with st.chat_message("assistant"):
                        st.markdown(response)
                except Exception as e: 
                    error_message = f"Erro: {e}"
                    st.error(error_message)
                    st.session_state.messages.append({"role": "assistant", "content": error_message})

    with tab_explorer:
        st.subheader("Leitura, Resumo e √Åudio de Relat√≥rios")
        if 'action' in st.session_state and st.session_state.action:
            action_type, file_path = st.session_state.action
            
            if action_type == 'read_pdf_viewer':
                st.write("Exibindo PDF:")
                display_pdf(file_path)
            
            elif action_type == 'read_pdf_text':
                # Extrair nome do arquivo
                file_name = os.path.basename(file_path)
                
                st.subheader(f"üìÑ Texto Extra√≠do: {file_name}")
                
                with st.spinner("Extraindo texto do PDF..."):
                    try:
                        full_text = file_handler.get_full_pdf_text(file_path)
                        
                        # Mostrar estat√≠sticas do texto
                        word_count = len(full_text.split())
                        char_count = len(full_text)
                        
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("üìä Palavras", f"{word_count:,}")
                        with col2:
                            st.metric("üî§ Caracteres", f"{char_count:,}")
                        with col3:
                            st.metric("üìë P√°ginas (aprox.)", max(1, word_count // 250))
                        
                        # Bot√£o de download do texto
                        st.download_button(
                            label="üì• Baixar Texto (.txt)",
                            data=full_text,
                            file_name=f"texto_{file_name.replace('.pdf', '')}.txt",
                            mime="text/plain"
                        )
                        
                        # Op√ß√µes de visualiza√ß√£o
                        view_option = st.radio(
                            "Op√ß√µes de visualiza√ß√£o:",
                            ["üìñ Texto Completo", "üîç Primeiras 500 palavras", "üéØ Buscar no texto"]
                        )
                        
                        if view_option == "üìñ Texto Completo":
                            st.text_area("Conte√∫do do PDF", full_text, height=700)
                            
                        elif view_option == "üîç Primeiras 500 palavras":
                            words = full_text.split()
                            preview_text = " ".join(words[:500])
                            if len(words) > 500:
                                preview_text += "\n\n[... restante do texto omitido ...]"
                            st.text_area("Pr√©via do PDF (500 palavras)", preview_text, height=400)
                            
                        elif view_option == "üéØ Buscar no texto":
                            search_term = st.text_input("Digite o termo para buscar:")
                            if search_term:
                                # Buscar termo no texto (case insensitive)
                                import re
                                matches = re.finditer(re.escape(search_term), full_text, re.IGNORECASE)
                                match_positions = [(m.start(), m.end()) for m in matches]
                                
                                if match_positions:
                                    st.success(f"Encontradas {len(match_positions)} ocorr√™ncias de '{search_term}'")
                                    
                                    # Mostrar contexto das primeiras 5 ocorr√™ncias
                                    for i, (start, end) in enumerate(match_positions[:5]):
                                        context_start = max(0, start - 100)
                                        context_end = min(len(full_text), end + 100)
                                        context = full_text[context_start:context_end]
                                        
                                        # Destacar o termo encontrado
                                        highlighted = context.replace(
                                            search_term, f"**{search_term}**"
                                        )
                                        
                                        st.write(f"**Ocorr√™ncia {i+1}:**")
                                        st.write(f"...{highlighted}...")
                                        st.write("---")
                                else:
                                    st.warning(f"Termo '{search_term}' n√£o encontrado no texto.")
                                    
                    except Exception as e:
                        st.error(f"Erro ao extrair texto do PDF: {e}")
                        st.info("üí° Tente a op√ß√£o 'Ler PDF (Visualizador)' como alternativa.")
            
            elif action_type == 'summarize':
                with st.spinner("Gerando resumo..."):
                    full_text = file_handler.get_full_pdf_text(file_path)
                    summarizer = llm_services.get_summarizer_chain()
                    summary = summarizer.invoke({"text_to_summarize": full_text}).content
                    st.text_area("Resumo", summary, height=600)

            elif action_type in ['listen_summary', 'listen_full']:
                # Extrair nome do arquivo a partir do caminho
                file_name = os.path.basename(file_path)
                
                if action_type == 'listen_summary':
                    with st.spinner("Gerando resumo e √°udio..."):
                        # Gerar resumo
                        full_text = file_handler.get_full_pdf_text(file_path)
                        summarizer = llm_services.get_summarizer_chain()
                        summary_text = summarizer.invoke({"text_to_summarize": full_text}).content
                        
                        # Mostrar resumo
                        st.subheader("üìù Resumo do Relat√≥rio")
                        st.text_area("Resumo", summary_text, height=300)
                        
                        # Converter resumo para √°udio
                        with st.spinner("Convertendo resumo para √°udio..."):
                            audio_content = llm_services.text_to_speech(summary_text)
                            
                            if audio_content:
                                st.subheader("üéß √Åudio do Resumo")
                                st.audio(audio_content, format='audio/mp3')
                                
                                # Bot√£o de download do √°udio
                                st.download_button(
                                    label="üì• Baixar √Åudio do Resumo",
                                    data=audio_content,
                                    file_name=f"resumo_{file_name.replace('.pdf', '')}.mp3",
                                    mime="audio/mp3"
                                )
                            else:
                                st.error("Falha ao gerar √°udio do resumo.")
                
                else: # listen_full
                    with st.spinner("Gerando √°udio do relat√≥rio completo... Isso pode demorar!"):
                        full_text = file_handler.get_full_pdf_text(file_path)
                        
                        # Dividir o texto em chunks menores para a API de TTS
                        text_splitter = RecursiveCharacterTextSplitter(
                            chunk_size=4000,  # Tamanho m√°ximo de chunk para a API de TTS
                            chunk_overlap=200
                        )
                        text_chunks = text_splitter.split_text(full_text)
                        
                        st.info(f"Processando {len(text_chunks)} partes do relat√≥rio...")
                        
                        # Criar progress bar
                        progress_bar = st.progress(0)
                        progress_text = st.empty()
                        
                        audio_contents = []
                        for i, chunk in enumerate(text_chunks):
                            progress_text.text(f"Convertendo parte {i+1}/{len(text_chunks)} para √°udio...")
                            progress_bar.progress((i + 1) / len(text_chunks))
                            
                            audio_content = llm_services.text_to_speech(chunk)
                            if audio_content:
                                audio_contents.append(audio_content)
                            else:
                                st.error(f"Falha ao gerar √°udio para a parte {i+1}.")
                                break
                        
                        # Limpar progress indicators
                        progress_bar.empty()
                        progress_text.empty()
                        
                        if audio_contents:
                            st.subheader("üéß √Åudio do Relat√≥rio Completo")
                            
                            # Tentar concatenar √°udios
                            with st.spinner("Concatenando arquivos de √°udio..."):
                                final_audio = llm_services.concatenate_audio_files(audio_contents)
                            
                            if final_audio:
                                st.success(f"√Åudio completo gerado com {len(audio_contents)} partes!")
                                st.audio(final_audio, format='audio/mp3')
                                
                                # Bot√£o de download
                                st.download_button(
                                    label="üì• Baixar √Åudio Completo",
                                    data=final_audio,
                                    file_name=f"audio_completo_{file_name.replace('.pdf', '')}.mp3",
                                    mime="audio/mp3"
                                )
                            else:
                                st.warning("Concatena√ß√£o n√£o dispon√≠vel. Reproduzindo primeira parte:")
                                st.audio(audio_contents[0], format='audio/mp3')
                                
                                # Op√ß√£o para baixar partes individuais
                                st.subheader("üì• Download das Partes Individuais")
                                for i, audio_content in enumerate(audio_contents):
                                    st.download_button(
                                        label=f"Parte {i+1}/{len(audio_contents)}",
                                        data=audio_content,
                                        file_name=f"parte_{i+1}_{file_name.replace('.pdf', '')}.mp3",
                                        mime="audio/mp3",
                                        key=f"download_part_{i}"
                                    )
                        else:
                            st.error("Nenhum √°udio foi gerado.")
            
            # Limpa a a√ß√£o para evitar reexecu√ß√£o
            st.session_state.action = None

    with tab_insights:
        # Mostrar modelo ativo
        selected_model = st.session_state.get('selected_model', config.LLM_MODEL_NAME)
        st.subheader("üí° Insights Autom√°ticos dos Relat√≥rios")
        st.info(f"ü§ñ **Modelo ativo:** {config.AVAILABLE_LLM_MODELS.get(selected_model, selected_model)}")
        
        # Verificar se h√° documentos processados
        doc_count = vector_manager.count_documents()
        if doc_count == 0:
            st.warning("‚ö†Ô∏è Nenhum relat√≥rio foi processado ainda. Fa√ßa upload e processe documentos primeiro.")
            st.info("üìù V√° para a barra lateral e:")
            st.write("1. Carregar novos relat√≥rios")
            st.write("2. Processar relat√≥rios")
            st.write("3. Volte aqui para ver os insights!")
            return
        
        st.info(f"üìä Analisando {doc_count} chunks de dados dos relat√≥rios processados...")
        
        # Bot√µes para diferentes tipos de insights
        col1, col2, col3 = st.columns(3)
        
        with col1:
            if st.button("üìã Resumo Executivo", use_container_width=True):
                st.session_state.insight_action = "market_summary"
        
        with col2:
            if st.button("üìä M√©tricas Chave", use_container_width=True):
                st.session_state.insight_action = "key_metrics"
        
        with col3:
            if st.button("üîç An√°lise Detalhada", use_container_width=True):
                st.session_state.insight_action = "detailed_insights"
        
        # Processar a√ß√µes de insights
        if 'insight_action' in st.session_state and st.session_state.insight_action:
            action = st.session_state.insight_action
            retriever = vector_manager.get_retriever(k=6)  # Mais contexto para insights
            
            if action == "market_summary":
                st.subheader("üìã Resumo Executivo do Mercado")
                with st.spinner("Gerando resumo executivo..."):
                    selected_model = st.session_state.get('selected_model', config.LLM_MODEL_NAME)
                    summary = llm_services.generate_market_summary(retriever, model_name=selected_model)
                    st.markdown(summary)
                    
                    # Bot√£o para download
                    st.download_button(
                        label="üì• Baixar Resumo Executivo",
                        data=summary,
                        file_name="resumo_executivo_fii.txt",
                        mime="text/plain"
                    )
            
            elif action == "key_metrics":
                st.subheader("üìä M√©tricas Chave Extra√≠das")
                with st.spinner("Extraindo m√©tricas dos relat√≥rios..."):
                    selected_model = st.session_state.get('selected_model', config.LLM_MODEL_NAME)
                    metrics = llm_services.extract_key_metrics(retriever, model_name=selected_model)
                    
                    if "error" in metrics:
                        st.error(metrics["error"])
                    else:
                        st.markdown(metrics.get("metrics", "Nenhuma m√©trica encontrada"))
                        
                        # Bot√£o para download
                        if metrics.get("metrics"):
                            st.download_button(
                                label="üì• Baixar M√©tricas",
                                data=metrics["metrics"],
                                file_name="metricas_chave_fii.txt",
                                mime="text/plain"
                            )
            
            elif action == "detailed_insights":
                st.subheader("üîç An√°lise Detalhada dos Relat√≥rios")
                with st.spinner("Gerando insights detalhados... Isso pode levar alguns minutos."):
                    selected_model = st.session_state.get('selected_model', config.LLM_MODEL_NAME)
                    insights = llm_services.generate_insights_from_documents(retriever, model_name=selected_model)
                    
                    # Criar abas para diferentes insights
                    insight_tabs = st.tabs([
                        "üè¢ FIIs Principais", 
                        "üí∞ Rendimentos", 
                        "üèóÔ∏è Setores", 
                        "üìà Recomenda√ß√µes",
                        "‚ö†Ô∏è Riscos & Oportunidades",
                        "üìä Tend√™ncias"
                    ])
                    
                    queries = list(insights.keys())
                    
                    for i, tab in enumerate(insight_tabs):
                        with tab:
                            if i < len(queries):
                                query = queries[i]
                                insight = insights[query]
                                st.markdown(f"**Pergunta:** {query}")
                                st.markdown("---")
                                st.markdown(insight)
                    
                    # Bot√£o para download de todos os insights
                    all_insights_text = "\n\n".join([f"PERGUNTA: {q}\n\nRESPOSTA: {a}\n{'='*50}" for q, a in insights.items()])
                    st.download_button(
                        label="üì• Baixar Todos os Insights",
                        data=all_insights_text,
                        file_name="insights_completos_fii.txt",
                        mime="text/plain"
                    )
            
            # Limpar a√ß√£o ap√≥s processamento
            st.session_state.insight_action = None
        
        # Se√ß√£o de informa√ß√µes adicionais
        with st.expander("‚ÑπÔ∏è Como funcionam os Insights"):
            st.write("""
            **Os insights s√£o gerados automaticamente usando:**
            
            1. **RAG (Retrieval-Augmented Generation)**: Busca informa√ß√µes relevantes nos documentos
            2. **IA Generativa**: Analisa e sintetiza as informa√ß√µes encontradas  
            3. **Prompts Especializados**: Perguntas espec√≠ficas para extrair insights valiosos
            
            **Tipos de Insights Dispon√≠veis:**
            - üìã **Resumo Executivo**: Vis√£o geral do mercado e recomenda√ß√µes
            - üìä **M√©tricas Chave**: Valores, rendimentos e dados num√©ricos
            - üîç **An√°lise Detalhada**: Insights segmentados por categoria
            
            **Dica**: Quanto mais documentos processados, mais ricos ser√£o os insights!
            """)

if __name__ == '__main__':
    main()