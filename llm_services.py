
"""M√≥dulo de Servi√ßos de LLM

Encapsula intera√ß√µes com a API da OpenAI: Agente, Resumo e TTS.
"""
from io import BytesIO
from openai import OpenAI
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain.agents import Tool, initialize_agent, AgentType
from langchain_community.tools import DuckDuckGoSearchRun
from langchain.memory import ConversationBufferMemory

from config import LLM_MODEL_NAME, TTS_VOICE

# Cliente OpenAI para TTS ser√° inicializado quando necess√°rio
client = None

def get_openai_client():
    """Retorna cliente OpenAI inicializado."""
    global client
    if client is None:
        client = OpenAI()
    return client

def get_summarizer_chain(model_name=None):
    """Cria e retorna uma cadeia para resumir textos."""
    if model_name is None:
        model_name = LLM_MODEL_NAME
    llm = ChatOpenAI(model_name=model_name, temperature=0)
    prompt = PromptTemplate.from_template(
        "Fa√ßa um resumo conciso e bem estruturado em portugu√™s do seguinte texto:\n\n{text_to_summarize}\n\nRESUMO:"
    )
    return prompt | llm

def generate_insights_from_documents(retriever, model_name=None):
    """Gera insights autom√°ticos dos documentos usando RAG."""
    if model_name is None:
        model_name = LLM_MODEL_NAME
    llm = ChatOpenAI(model_name=model_name, temperature=0.3)
    
    # Queries para extrair insights espec√≠ficos
    insight_queries = [
        "Quais s√£o os principais FIIs mencionados e suas caracter√≠sticas?",
        "Quais s√£o os rendimentos e dividendos mais destacados?",
        "Quais setores de investimento imobili√°rio s√£o mais mencionados?",
        "Quais s√£o as principais recomenda√ß√µes de investimento?",
        "Quais s√£o os riscos e oportunidades identificados?",
        "Quais s√£o as tend√™ncias do mercado imobili√°rio mencionadas?"
    ]
    
    insights = {}
    
    for query in insight_queries:
        try:
            # Buscar documentos relevantes
            docs = retriever.invoke(query)
            if docs:
                # Combinar contexto dos documentos
                context = "\n\n".join([doc.page_content for doc in docs[:3]])
                
                # Prompt para gerar insight
                prompt = f"""
                Com base no seguinte contexto dos relat√≥rios financeiros, responda de forma clara e estruturada:

                PERGUNTA: {query}

                CONTEXTO:
                {context}

                RESPOSTA (seja espec√≠fico e cite dados quando poss√≠vel):
                """
                
                response = llm.invoke(prompt)
                insights[query] = response.content
                
        except Exception as e:
            insights[query] = f"Erro ao gerar insight: {e}"
    
    return insights

def generate_market_summary(retriever, model_name=None):
    """Gera um resumo executivo do mercado baseado nos documentos."""
    if model_name is None:
        model_name = LLM_MODEL_NAME
    llm = ChatOpenAI(model_name=model_name, temperature=0.2)
    
    try:
        # Buscar documentos para an√°lise geral
        docs = retriever.invoke("resumo investimentos FII mercado tend√™ncias")
        
        if not docs:
            return "N√£o h√° documentos suficientes para gerar resumo do mercado."
        
        # Combinar contexto
        context = "\n\n".join([doc.page_content for doc in docs[:4]])
        
        prompt = f"""
        Voc√™ √© um analista financeiro especializado em FIIs. Baseado nos relat√≥rios fornecidos, 
        crie um RESUMO EXECUTIVO do mercado de Fundos Imobili√°rios.

        CONTEXTO DOS RELAT√ìRIOS:
        {context}

        Crie um resumo executivo com:
        1. **Situa√ß√£o Atual do Mercado**
        2. **Principais Oportunidades**  
        3. **Principais Riscos**
        4. **Recomenda√ß√µes Gerais**

        Seja objetivo, use dados espec√≠ficos quando dispon√≠veis, e mantenha linguagem profissional:
        """
        
        response = llm.invoke(prompt)
        return response.content
        
    except Exception as e:
        return f"Erro ao gerar resumo do mercado: {e}"

def extract_key_metrics(retriever, model_name=None):
    """Extrai m√©tricas chave dos relat√≥rios."""
    try:
        # Buscar documentos com dados num√©ricos
        docs = retriever.invoke("valor pre√ßo rentabilidade dividend yield cota√ß√£o R$")
        
        if not docs:
            return {}
        
        if model_name is None:
            model_name = LLM_MODEL_NAME
        llm = ChatOpenAI(model_name=model_name, temperature=0)
        context = "\n\n".join([doc.page_content for doc in docs[:3]])
        
        prompt = f"""
        Extraia APENAS os dados num√©ricos e m√©tricas espec√≠ficas do seguinte contexto.
        Retorne em formato estruturado:

        CONTEXTO:
        {context}

        Extraia e organize:
        - Valores de FIIs (formato: C√ìDIGO: R$ X,XX)
        - Rentabilidades/Yields (formato: X,XX% ou X.XX%)
        - Dividendos (formato: R$ X,XX por cota)
        
        Seja preciso e cite apenas valores que est√£o expl√≠citos no texto:
        """
        
        response = llm.invoke(prompt)
        return {"metrics": response.content}
        
    except Exception as e:
        return {"error": f"Erro ao extrair m√©tricas: {e}"}

def text_to_speech(text):
    """Converte texto para √°udio usando a API da OpenAI."""
    try:
        client = get_openai_client()
        response = client.audio.speech.create(
            model="tts-1",
            voice=TTS_VOICE,
            input=text
        )
        # Retorna os bytes diretamente para compatibilidade com st.audio
        return response.content
    except Exception as e:
        print(f"Erro na API de TTS: {e}")
        return None

def concatenate_audio_files(audio_contents_list):
    """Concatena m√∫ltiplos arquivos de √°udio usando pydub."""
    try:
        from pydub import AudioSegment
        from io import BytesIO
        
        if not audio_contents_list:
            return None
            
        # Carregar o primeiro √°udio
        combined = AudioSegment.from_file(BytesIO(audio_contents_list[0]), format="mp3")
        
        # Concatenar os demais
        for audio_content in audio_contents_list[1:]:
            audio_segment = AudioSegment.from_file(BytesIO(audio_content), format="mp3")
            combined += audio_segment
        
        # Exportar para bytes
        output_buffer = BytesIO()
        combined.export(output_buffer, format="mp3")
        return output_buffer.getvalue()
        
    except ImportError:
        print("pydub n√£o est√° dispon√≠vel para concatena√ß√£o de √°udio")
        return audio_contents_list[0] if audio_contents_list else None
    except Exception as e:
        print(f"Erro ao concatenar √°udios: {e}")
        return audio_contents_list[0] if audio_contents_list else None

def setup_agent(retriever, model_name=None):
    """Inicializa e retorna o agente com suas ferramentas e mem√≥ria."""
    if model_name is None:
        model_name = LLM_MODEL_NAME
    llm = ChatOpenAI(model_name=model_name, temperature=0.1)
    
    # Template espec√≠fico para an√°lise de investimentos
    template = """Use o contexto dos documentos de investimento para responder √† pergunta do usu√°rio de forma precisa e √∫til.

Contexto dos relat√≥rios de investimento:
{context}

Pergunta do usu√°rio: {question}

Instru√ß√µes para sua resposta:
1. Analise cuidadosamente o contexto fornecido pelos documentos
2. Se a informa√ß√£o solicitada estiver no contexto, forne√ßa uma resposta clara e detalhada
3. Inclua valores espec√≠ficos, datas e dados precisos quando dispon√≠veis
4. Se a informa√ß√£o n√£o estiver no contexto, informe que n√£o foi encontrada nos documentos processados
5. Mantenha o foco na an√°lise de investimentos e dados financeiros

Resposta detalhada:"""

    prompt = PromptTemplate(
        template=template,
        input_variables=["context", "question"]
    )
    
    qa_chain = RetrievalQA.from_chain_type(
        llm=llm, 
        chain_type="stuff", 
        retriever=retriever,
        chain_type_kwargs={"prompt": prompt}
    )
    
    # Wrapper function para a ferramenta RAG
    def analyze_investment_reports(question):
        """Analisa relat√≥rios de investimento para responder perguntas espec√≠ficas."""
        try:
            print(f"üîç Analisando pergunta: {question}")
            result = qa_chain.invoke({"query": question})
            print(f"üìÑ Resultado da busca: {result['result'][:200]}...")
            return result["result"]
        except Exception as e:
            print(f"‚ùå Erro ao acessar documentos: {str(e)}")
            return f"Erro ao acessar os documentos: {str(e)}"

    report_analyzer_tool = Tool(
        name="Consultar_Relat√≥rios_Investimento",
        func=analyze_investment_reports,
        description="""SEMPRE use esta ferramenta para perguntas sobre FIIs, c√≥digos de fundos, valores patrimoniais, rendimentos, dividendos ou qualquer informa√ß√£o espec√≠fica de investimentos. Esta ferramenta busca nos relat√≥rios financeiros processados e carregados no sistema. Input: pergunta sobre investimentos."""
    )
    
    # Ferramenta de busca na web para informa√ß√µes gerais
    web_search_tool = DuckDuckGoSearchRun()
    
    tools = [report_analyzer_tool, web_search_tool]
    
    # Configurar a mem√≥ria para o agente
    memory = ConversationBufferMemory(memory_key="chat_history", return_messages=True)

    # Inicializar agente com configura√ß√£o padr√£o mas instru√ß√µes espec√≠ficas
    agent_executor = initialize_agent(
        tools,
        llm,
        agent=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,
        verbose=True,
        memory=memory,
        handle_parsing_errors=True,
        max_iterations=4,
        early_stopping_method="generate"
    )
    
    return agent_executor
